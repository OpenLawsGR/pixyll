---
layout:     post
title:      Methodology!
date:       2015-08-30 10:03:00
summary:    A general layout of the proposed methodology.
categories: legislation
---

In this post we present a general layout of the methodology that we are following:

1. __Collection of Greek Legislation.__ Initially, there is the need to collect all greek law documents that are published from the [National Printing Service (NPS)](http://www.et.gr) in the Government Gazzette. In a [previous post](http://www.openlaws.gr/legislation/code/2015/06/22/scrapying-greek-laws/) we have shown in detail how a crawler that undertakes this task can be implemented.
2. __Transformation of Files to Plain Text Format.__ Law documents are published as PDF files and as a result there is the need to transform them in a format that can easily be processed. We use the 'pdftotext' open source utility for Linux to transform PDF files to plain text documents. Older PDF files (usually before 2004) contain scanned images and since OCR processing can be erroneous and these errors are detrimental to pattern matching, we decided to <u>exclude these files and limit the application of our system to newest laws</u>. OCR training is out of the scope of this project, however it is an extension that we are willing to examine in the future.
3. __Distinction of Different Legislative Text Types.__ Each issue (PDF file) of the Government Gazzette may contain different types of legislative texts (e.g. laws, presidential decrees, ministerial decisions etc.). As our work currently focuses solely on laws, we need to distinguish laws from other legislative types residing in the same file. This is achievable by identifying the text patterns that flag the existence of a law and with the application of regular expressions one is able to isolate the text of each law.
4. __Law Text Preprocessing.__ Law text preprocessing is an important phase of the analysis cycle as it corrects several errors, either already present in the PDF files or produced during the previous steps. Such a process is expected to facilitate future analysis steps and natural language processing. In this phase, regular expressions can be used to remove irrelevant text that is transferred to the plain text files when transforming the PDF files: PDF page numbering, digital signature text, original file’s headers and footers, characters that are considered as garbage etc. Moreover, words divided by hyphens at the end of lines are fixed by concatenation. Finally, some abbreviations are temporarily substituted by the full words, as our first experimentations with the python suite [NLTK](http://www.nltk.org/), which provides tools for natural language processing, showed that they sometimes cause problems, e.g. resulting in wrong sentence segmentation.
5. __Structural Analysis.__ In order to automatically perform transformations to a law's content according to a modification, it is necessary to be aware of the structure of each law. Modifications refer to structural elements (such as articles, paragraphs, sub-paragraphs etc.) that a reader can easily search and identify within the text. However, a machine needs to analyze the text to recognize these elements. We are currently working on a module that parses each law text, performs structural analysis and identifies the structural elements. Laws’ structure follows distinct patterns, in the sense that laws should be written according to rules set by the Central Legislatorial Committee that explicitly define the structural parts of the text. Our module is based on regular expressions that match the patterns that occur according to these rules. After the analysis, we intend to store each law in XML format for internal representation purposed, which allows for a hierarchical layout of nodes, each one corresponding to a structural element.
6. __Identification and Automatic Application of Modifications.__ The last step of the methodology for the implementation of our system involves the identification of modifications in all text files and their recurrent application, in a proper chronological order, on the original law text they refer to, for the consolidation of all law versions. A modification may refer to an addition, suppression or substitution of a text portion. The verbs that are used to declare each case are usually the same or belong to a list of synonyms and can be used to detect possible modifications. Each candidate text portion should get further analyzed in order to detect if it follows a modification’s pattern (e.g. containing references to structural elements of another law) or it happens to appear within the law content as a simple verb occurrence. When a modification is identified and categorized as one of the three cases, a semantic and syntactic analysis will reveal which elements should change (e.g. a specific article of a law) and how (e.g. a specific text should be added at the beginning of that article). When all modifications are identified and analyzed, a script should traverse all laws and transform the appropriate laws’ texts according to the defined actions. The identification of the position of each modification’s referencing elements within the files should be straightforward due to the structural analysis presented in the previous step. When a new version of a law is produced, it will be committed and pushed to the version control repository.

Steps 1-4 are already successfully implemented. Step 5 is almost done and we will soon report on our respective work. Step 6 is still under design and normally we may need to reconsider some of our thoughts.

